# -*- coding: utf-8 -*-
"""Submission_Predictive_Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1clBn-MjnP_cFTvLUntmWVW52FM9KMQ8N

# Collecting Data

Pada tahap ini akan mengimpor seluruh library dari projek
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import yfinance as yf
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.metrics import mean_absolute_error, mean_squared_error
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

"""Pada tahap ini kita akan mengambil secara langsung dataset dari yahoo finance terkait saham dari bank mandiri"""

data = yf.download("BMRI.JK", start="2015-01-01", end="2025-05-25")

"""tahap mengecek data"""

data

"""tahap mengecek tipe data"""

data.dtypes

"""Data terdapat 2483 baris dan 29 kolom"""

data.shape

"""# Preprocessing

pada tahapan ini untuk melakukan pengecekan terhadap nilai kosong pada data
"""

data.isnull().sum()

"""melihat persebaran harga close pada dataset"""

plt.plot(data['Close'])
plt.title('Harga Close BMRI.JK')
plt.show()

"""feature engineering untuk menghitung rata-rata harga penutupan (Close) dalam jangka waktu tertentu. Fungsi compute_rsi menghitung indikator RSI dengan periode default 14 hari. Menghitung standar deviasi dari harga penutupan selama 20 hari terakhir."""

# Moving Average (7 hari dan 30 hari)
data['MA7'] = data['Close'].rolling(window=7).mean()
data['MA30'] = data['Close'].rolling(window=30).mean()

# RSI (Relative Strength Index)
def compute_rsi(series, period=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

data['RSI'] = compute_rsi(data['Close'])

# Volatilitas (standar deviasi 20 hari)
data['Volatility'] = data['Close'].rolling(window=20).std()

"""disini dilakukan ekstraksi informasi waktu (kalender) dari indeks tanggal dalam DataFrame data."""

data['Day_of_Week'] = data.index.dayofweek
data['Month'] = data.index.month

"""Lalu dilakukan pengunduhan data historis indeks IHSG (Indeks Harga Saham Gabungan) dan menyimpan harga penutupannya (Close) ke dalam DataFrame data."""

ihsg = yf.download("^JKSE", start="2015-01-01", end="2025-05-25")
data['IHSG_Close'] = ihsg['Close']

"""Feature engineering membentuk kolom baru dengan menghitung dan memprediksi perubahan persentase harga penutupan (Close) dari satu hari ke hari berikutnya"""

data['Return'] = data['Close'].pct_change().shift(-1)  # Persentase kenaikan

"""menampilkan data"""

data

"""menghapus data bernilai null pada dataset"""

data = data.dropna()

"""melihat kolom apa saja yang terbentuk"""

data.columns

"""menyederhanakan bentuk kolom agar mudah diproses"""

# Gabungkan level Price dan Ticker menjadi satu nama kolom
data.columns = [f"{price}_{ticker}" if ticker else price for price, ticker in data.columns]

"""melihat update kolomnya berubah nama menjadi apa saja"""

data.columns

"""Melakukan pemilihan fitur numerik yang akan dinormalisasi, lalu menentukan target akan dari kolom mana, melakukan normalisasi pada fitur terpilih lalu melakukan one hot encode pada kolom kategorikal dan menghapus baris yang null jika ada, kemudian mencetak semua kolom yang ada"""

numeric_columns = [
    'Open_BMRI.JK', 'High_BMRI.JK', 'Low_BMRI.JK', 'Close_BMRI.JK',
    'Volume_BMRI.JK', 'MA7', 'MA30', 'RSI', 'Volatility', 'IHSG_Close'
]

# Kolom target
target = 'Return'

# Normalisasi fitur
feature_scaler = MinMaxScaler()
data[numeric_columns] = feature_scaler.fit_transform(data[numeric_columns])

# Normalisasi target (Return) secara terpisah
target_scaler = MinMaxScaler()
data['Scaled_Return'] = target_scaler.fit_transform(data[[target]])

# One-hot encoding untuk kolom kategorikal
data = pd.get_dummies(data, columns=['Day_of_Week', 'Month'], prefix=['Day', 'Month'])

# Hapus baris dengan nilai NaN (akibat feature engineering atau shift)
data = data.dropna()

# Tampilkan kolom untuk memastikan
print("Kolom setelah normalisasi dan encoding:", data.columns.tolist())

"""melakukan konversi dari false dan true isi kolom day 0 dan seterusnya pada sebelumnya menjadi boolean 0 dan 1 agar bisa diproses oleh sistem"""

# Asumsi 'data' adalah DataFrame setelah one-hot encoding
# Identifikasi kolom boolean (Day_* dan Month_*)
boolean_columns = [col for col in data.columns if col.startswith('Day_') or col.startswith('Month_')]

# Ubah False/True menjadi 0/1
for col in boolean_columns:  # Perbaikan: ganti 'boolean Benutzercolumns' menjadi 'boolean_columns'
    data[col] = data[col].astype(int)

# Verifikasi perubahan
print("Tipe data setelah konversi:")
print(data[boolean_columns].dtypes)
print("\nContoh data setelah konversi:")
print(data[boolean_columns].head())

"""# Modelling

Memasuki tahap modelling disini dilakukan pemilihan terhadap fitur dan target
"""

features = [
    'Open_BMRI.JK', 'High_BMRI.JK', 'Low_BMRI.JK', 'Close_BMRI.JK',
    'Volume_BMRI.JK', 'MA7', 'MA30', 'RSI', 'Volatility', 'IHSG_Close'
] + [col for col in data.columns if col.startswith('Day_') or col.startswith('Month_')]
target = 'Scaled_Return'

"""- Modelling dilakukan dengan model LSTM, diawali dengan Mengubah data time series menjadi format sequence agar bisa diproses oleh model LSTM,
- Setiap input (X) adalah blok dari seq_length baris berturut-turut dari fitur.
Output (y) adalah nilai target (Scaled_Return) pada baris setelah sequence tersebut.
- Lalu dibuat panjang seq nya 30 hari yang berarti model akan dilatih untuk melihat tren pada 30 hari untuk memprediksi return besok
- Lalu splitting dilakukan dengan membagi menjadi 80% data latih dan 20%  data uji
- Lalu dibuat arsitektur LSTM seperti ini :

> Input Layer:

input_shape=(seq_length, len(features))
seq_length: panjang sequence (jumlah hari historis)
len(features): jumlah fitur
> LSTM Layer 1:

50 unit neuron
return_sequences=True: mengirim output ke layer LSTM berikutnya
> Dropout Layer 1:

Untuk mencegah overfitting (dropout rate 20%)
> LSTM Layer 2:

50 unit neuron
return_sequences=False: karena tidak ada LSTM layer berikutnya
> Dropout Layer 2:
Dropout rate 20%

> Output Layer:
Hanya 1 neuron, karena memprediksi 1 nilai (Scaled_Return)

> Loss Function:
mse (Mean Squared Error): cocok untuk regresi numerik\

> Optimizer:
Adam: optimizer adaptif yang umum digunakan

- Lalu model dilatih dengan parameter berikut :
> epochs=50, model akan melewati seluruh data latih sebanyak 50 kali

> batch_size=32: ukuran batch per iterasi pelatihan

> validation_split=0.1: 10% data latih digunakan untuk validasi selama pelatihan

- Lalu melakukan prediksi pada data uji (X_test)
Hasilnya masih dalam skala normalisasi (0â€“1)

- Mengembalikan ke skala asli dengan inverse transform

- dan diakhiri dengan menghitung performansi model yang telah dilatih dengan metriks mse dan mae
"""

# Buat sequence
def create_sequences(data, seq_length, features, target):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[features].iloc[i:i+seq_length].values)
        y.append(data[target].iloc[i+seq_length])
    return np.array(X), np.array(y)

seq_length = 30
X, y = create_sequences(data, seq_length, features, 'Scaled_Return')

# Bagi data
train_size = int(0.8 * len(X))
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Latih model LSTM
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(seq_length, len(features)), return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(50, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)

# Prediksi pada data pengujian
y_pred = model.predict(X_test)

# Kembalikan y_test dan y_pred ke skala asli
y_test_unscaled = target_scaler.inverse_transform(y_test.reshape(-1, 1))
y_pred_unscaled = target_scaler.inverse_transform(y_pred)

# Hitung MAE dan MSE
mae = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
mse = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print(f"Mean Absolute Error (MAE): {mae:.6f}")
print(f"Mean Squared Error (MSE): {mse:.6f}")

"""Membuat visualisasi perbandingan actual dan predict"""

import matplotlib.pyplot as plt
plt.plot(y_test_unscaled, label='Actual Return')
plt.plot(y_pred_unscaled, label='Predicted Return')
plt.legend()
plt.title('Actual vs Predicted Return')
plt.show()

"""# Hyperparamter tuning

Hyperparameter tuning dilakukan dengan membangun arsitektur LSTM dengan hyperparameter yang bisa diatur, memasukkan semua parameter yang akan diujikan, Semua kombinasi dari parameter ini akan dicoba satu per satu. Lalu Melakukan nested loop untuk mencoba semua kombinasi hyperparameter. Kemudian menyimpan hasil terbaik
"""

# Buat sequence
def create_sequences(data, seq_length, features, target):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[features].iloc[i:i+seq_length].values)
        y.append(data[target].iloc[i+seq_length])
    return np.array(X), np.array(y)

seq_length = 30
X, y = create_sequences(data, seq_length, features, 'Scaled_Return')

# Bagi data
train_size = int(0.8 * len(X))
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Definisikan model LSTM dengan hyperparameter yang dituning
def build_lstm_model(units=100, dropout_rate=0.3, learning_rate=0.001):
    model = Sequential()
    model.add(LSTM(units, activation='relu', input_shape=(seq_length, len(features)), return_sequences=True))
    model.add(Dropout(dropout_rate))
    model.add(LSTM(units, activation='relu', return_sequences=True))
    model.add(Dropout(dropout_rate))
    model.add(LSTM(units // 2, activation='relu'))  # Tambah layer ketiga dengan unit lebih kecil
    model.add(Dropout(dropout_rate))
    model.add(Dense(1))
    optimizer = Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer, loss='mse')
    return model

# Parameter untuk tuning
units_list = [100, 128]  # Coba jumlah unit berbeda
dropout_rates = [0.3, 0.4]  # Coba dropout rate berbeda
learning_rates = [0.001, 0.0001]  # Coba learning rate berbeda
batch_sizes = [16, 32]  # Coba batch size berbeda

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Loop untuk mencoba kombinasi hyperparameter
best_mae = float('inf')
best_params = {}
results = []

for units in units_list:
    for dropout_rate in dropout_rates:
        for learning_rate in learning_rates:
            for batch_size in batch_sizes:
                print(f"\nMencoba: units={units}, dropout={dropout_rate}, lr={learning_rate}, batch_size={batch_size}")

                # Bangun dan latih model
                model = build_lstm_model(units=units, dropout_rate=dropout_rate, learning_rate=learning_rate)
                model.fit(X_train, y_train, epochs=100, batch_size=batch_size,
                          validation_split=0.1, callbacks=[early_stopping], verbose=1)

                # Prediksi pada data pengujian
                y_pred = model.predict(X_test)

                # Kembalikan ke skala asli
                y_test_unscaled = target_scaler.inverse_transform(y_test.reshape(-1, 1))
                y_pred_unscaled = target_scaler.inverse_transform(y_pred)

                # Hitung MAE dan MSE
                mae = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
                mse = mean_squared_error(y_test_unscaled, y_pred_unscaled)

                print(f"MAE: {mae:.6f}, MSE: {mse:.6f}")

                # Simpan hasil
                results.append({
                    'units': units,
                    'dropout_rate': dropout_rate,
                    'learning_rate': learning_rate,
                    'batch_size': batch_size,
                    'mae': mae,
                    'mse': mse
                })

                # Update model terbaik
                if mae < best_mae:
                    best_mae = mae
                    best_params = {
                        'units': units,
                        'dropout_rate': dropout_rate,
                        'learning_rate': learning_rate,
                        'batch_size': batch_size,
                        'mae': mae,
                        'mse': mse
                    }

# Tampilkan hasil terbaik
print("\nHasil Tuning Terbaik:")
print(f"Parameter: {best_params}")
print(f"MAE Terbaik: {best_params['mae']:.6f}")
print(f"MSE Terbaik: {best_params['mse']:.6f}")

# Tampilkan semua hasil
results_df = pd.DataFrame(results)
print("\nSemua Hasil Tuning:")
print(results_df.sort_values(by='mae'))

"""Melatih model LSTM dengan parameter terbaik hasil hyperparameter tuning"""

# Asumsi 'data', 'features', dan 'target_scaler' sudah didefinisikan
# Pastikan data sudah dinormalisasi dan one-hot encoded
# Contoh pengingat normalisasi (jalankan jika belum):
"""
from sklearn.preprocessing import MinMaxScaler
numeric_columns = [
    'Open_BMRI.JK', 'High_BMRI.JK', 'Low_BMRI.JK', 'Close_BMRI.JK',
    'Volume_BMRI.JK', 'MA7', 'MA30', 'RSI', 'Volatility', 'IHSG_Close'
]
feature_scaler = MinMaxScaler()
data[numeric_columns] = feature_scaler.fit_transform(data[numeric_columns])
target_scaler = MinMaxScaler()
data['Scaled_Return'] = target_scaler.fit_transform(data[['Return']])
data = pd.get_dummies(data, columns=['Day_of_Week', 'Month'], prefix=['Day', 'Month'], dtype=int)
data = data.dropna()
features = numeric_columns + [col for col in data.columns if col.startswith('Day_') or col.startswith('Month_')]
"""

# Buat sequence
def create_sequences(data, seq_length, features, target):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[features].iloc[i:i+seq_length].values)
        y.append(data[target].iloc[i+seq_length])
    return np.array(X), np.array(y)

seq_length = 30
X, y = create_sequences(data, seq_length, features, 'Scaled_Return')

# Bagi data
train_size = int(0.8 * len(X))
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Bangun model dengan parameter terbaik
model = Sequential()
model.add(LSTM(100, activation='relu', input_shape=(seq_length, len(features)), return_sequences=True))
model.add(Dropout(0.4))
model.add(LSTM(100, activation='relu', return_sequences=True))
model.add(Dropout(0.4))
model.add(LSTM(50, activation='relu'))  # Layer ketiga dengan unit lebih kecil
model.add(Dropout(0.4))
model.add(Dense(1))
optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='mse')

# Early stopping untuk mencegah overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Latih model
model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.1,
          callbacks=[early_stopping], verbose=1)

# Prediksi pada data pengujian
y_pred = model.predict(X_test)

# Kembalikan ke skala asli
y_test_unscaled = target_scaler.inverse_transform(y_test.reshape(-1, 1))
y_pred_unscaled = target_scaler.inverse_transform(y_pred)

# Hitung MAE dan MSE
mae = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
mse = mean_squared_error(y_test_unscaled, y_pred_unscaled)

print(f"Mean Absolute Error (MAE): {mae:.6f}")
print(f"Mean Squared Error (MSE): {mse:.6f}")

# Visualisasi prediksi vs aktual
plt.figure(figsize=(12, 6))
plt.plot(y_test_unscaled, label='Actual Return', color='blue')
plt.plot(y_pred_unscaled, label='Predicted Return', color='orange')
plt.title('Actual vs Predicted Return (Best Model)')
plt.xlabel('Time')
plt.ylabel('Return (Percentage)')
plt.legend()
plt.show()

"""# Inference

Melakukan inference untuk menguji model agar memprediksi return untuk 10 hari kedepan
"""

# Prediksi Return untuk 10 hari ke depan
n_future_days = 10
future_returns = []
current_sequence = X[-1].copy()  # Ambil sequence terakhir dari data

for _ in range(n_future_days):
    pred = model.predict(current_sequence.reshape(1, seq_length, len(features)))
    future_returns.append(pred[0, 0])
    current_sequence = np.roll(current_sequence, -1, axis=0)
    current_sequence[-1, 0] = pred  # Update kolom pertama (misalnya, Scaled_Return)

# Kembalikan prediksi ke skala asli
future_returns_unscaled = target_scaler.inverse_transform(np.array(future_returns).reshape(-1, 1))

# Tampilkan prediksi
print("\nPrediksi Return Harian untuk 10 Hari ke Depan (%):")
for i, ret in enumerate(future_returns_unscaled):
    print(f"Hari {i+1}: {ret[0]:.6f}%")

# Visualisasi prediksi masa depan
plt.figure(figsize=(12, 6))
plt.plot(range(1, n_future_days + 1), future_returns_unscaled, label='Predicted Future Return', color='green')
plt.title('Predicted Return for Next 10 Days')
plt.xlabel('Day')
plt.ylabel('Return (Percentage)')
plt.legend()
plt.show()

